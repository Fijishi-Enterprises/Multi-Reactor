{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy import interpolate \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import date\n",
    "import datetime\n",
    "from myfunctions_multi_scale import *\n",
    "%matplotlib inline\n",
    "\n",
    "# Sensitivity analysis functions\n",
    "import SALib\n",
    "from SALib.sample import saltelli\n",
    "from SALib.analyze import sobol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umol_to_percent_DW 0.0014\n",
      "n_days 14.0\n",
      "Next0 110.0\n",
      "Nint0 1.05\n",
      "m0 0.19724999999999998\n",
      "S 35.0\n",
      "Nintcrit 2.0\n",
      "n_reactors 1.0\n",
      "Qp 459.5833333333333\n",
      "Qsea 224910.0\n",
      "Nsea 110.0\n",
      "dilution 0.0\n",
      "miu 0.027\n",
      "Nintmax 4.2\n",
      "Nintmin 0.7\n",
      "KN 1.2\n",
      "Ks 14.0\n",
      "Vmax 60.0\n",
      "Z 1.0\n",
      "KI 20.0\n",
      "K0 1.5\n",
      "Ka 0.15\n",
      "Topt 18.0\n",
      "Tmin 5.0\n",
      "Tmax 31.5\n",
      "n 2.0\n",
      "losses20 0.0016\n",
      "teta 1.047\n",
      "Sopt 18.0\n",
      "Smin 0.0\n",
      "Smax 45.0\n",
      "Shigh 30.0\n",
      "Slow 12.0\n"
     ]
    }
   ],
   "source": [
    "# importing parameters for validation with Reading data \n",
    "\n",
    "xval = pd.ExcelFile('../data/input.xlsx')\n",
    "dfval = xval.parse('Parameters_Reading',header=None)\n",
    "\n",
    "# assigmment of parameters to values: \n",
    "for key,val in zip(dfval.iloc[:][0],dfval.iloc[:][1]):\n",
    "    exec(key + '=val')\n",
    "    print(key,val)\n",
    "\n",
    "n_reactors = np.int(n_reactors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all data for model valodation (source: HOBO data from aerated cage in Reading - Alex Ch, 2017)\n",
    "\n",
    "period1i = datetime.datetime(2017, 4, 20)\n",
    "hour1i = 24 * (int(period1i.strftime(\"%j\"))-1) + 8\n",
    "\n",
    "period2i = datetime.datetime(2017, 5, 3)\n",
    "hour2i = 24 * (int(period2i.strftime(\"%j\"))-1) + 14\n",
    "\n",
    "period3i = datetime.datetime(2017, 5, 17)\n",
    "hour3i = 24 * (int(period3i.strftime(\"%j\"))-1) + 14\n",
    "\n",
    "period4i = datetime.datetime(2017, 6, 15)\n",
    "hour4i = 24 * (int(period4i.strftime(\"%j\"))-1) + 12\n",
    "\n",
    "period5i = datetime.datetime(2017, 6, 28)\n",
    "hour5i = 24 * (int(period5i.strftime(\"%j\"))-1) + 11\n",
    "\n",
    "x2 = pd.ExcelFile('../data/HOBO.xlsx')\n",
    "\n",
    "dfV1 = x2.parse('period1_PAR',header=None)\n",
    "dfV4 = x2.parse('period2_PAR',header=None)\n",
    "dfV5 = x2.parse('period3_PAR',header=None)\n",
    "\n",
    "#IV1 and TV1 based only on IMS and not on HOBO data\n",
    "\n",
    "IV2, TV2,IV2_average,TV2_average = [],[],[],[]\n",
    "for vali,valT in zip(dfV1.iloc[3:2488:1][5],dfV1.iloc[3:2488:1][3]):\n",
    "    IV2.append(vali)\n",
    "    TV2.append(float(valT))\n",
    "for i in range(1,len(IV2),4):\n",
    "    IV2_average.append(np.mean(IV2[i-1:i+3:1]))\n",
    "    TV2_average.append(np.mean(TV2[i-1:i+3:1]))\n",
    "\n",
    "IV3, TV3,IV3_average,TV3_average = [],[],[],[]\n",
    "for vali,valT in zip(dfV1.iloc[3+14*24*4:2488:1][5],dfV1.iloc[3+14*24*4:2488:1][3]):\n",
    "    IV3.append(vali)\n",
    "    TV3.append(float(valT))\n",
    "for i in range(1,len(IV3),4):\n",
    "    IV3_average.append(np.mean(IV3[i-1:i+3:1]))\n",
    "    TV3_average.append(np.mean(TV3[i-1:i+3:1]))\n",
    "    \n",
    "IV4, TV4,IV4_average,TV4_average = [],[],[],[]\n",
    "for vali,valT in zip(dfV4.iloc[13:1249:1][5],dfV4.iloc[13:1249:1][3]):\n",
    "    IV4.append(vali)\n",
    "    TV4.append(float(valT))\n",
    "for i in range(1,len(IV4),4):\n",
    "    IV4_average.append(np.mean(IV4[i-1:i+3:1]))\n",
    "    TV4_average.append(np.mean(TV4[i-1:i+3:1]))\n",
    "\n",
    "IV5, TV5,IV5_average,TV5_average = [],[],[],[]\n",
    "for vali,valT in zip(dfV5.iloc[7:1345:1][5],dfV5.iloc[7:1345:1][3]):\n",
    "    IV5.append(vali)\n",
    "    TV5.append(float(valT))\n",
    "for i in range(1,len(IV5),4):\n",
    "    IV5_average.append(np.mean(IV5[i-1:i+3:1]))\n",
    "    TV5_average.append(np.mean(TV5[i-1:i+3:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import of IMS I and T data - based on data from 2017:\n",
    "#ref: Chemodanov, A., Robin, A., Jinjikhashvily, G., Yitzhak, D., Liberzon, A., Israel, A., & Golberg, A. (2019).\n",
    "# Feasibility study of Ulva sp.(Chlorophyta) intensive cultivation in a coastal area of the Eastern Mediterranean Sea.\n",
    "# Biofuels, Bioproducts and Biorefining, 13(4), 864-877.\n",
    "dFI = pd.read_csv('../data/ims_data_2017_PAR.csv',encoding= 'unicode_escape',header=None)\n",
    "dfT = pd.read_csv('../data/ims_T_data_2017.csv',encoding= 'unicode_escape',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process IMS I and T Data\n",
    "\n",
    "# I data\n",
    "days = list(range(1,366))\n",
    "I = np.zeros(24*365)\n",
    "Temp = np.zeros(24*365-1-24)\n",
    "light_hours = list(range(5,19))\n",
    "for day in days:\n",
    "    for hour in light_hours:\n",
    "        I[(day - 1)*24 + hour] = float(dFI.iloc[day][hour-1])\n",
    "\n",
    "# T data\n",
    "annual_hours_short = list(range(2,2741*3-1))\n",
    "annual_hours = list(range(1,(366-1)*24+1))\n",
    "f0 = interpolate.interp1d(annual_hours, I,kind = 'linear')\n",
    "\n",
    "TV1 = []\n",
    "for valT in zip(dfT.iloc[1:2741:1][4]):\n",
    "    TV1.append(float(valT[0]))\n",
    "TV1[-1]\n",
    "\n",
    "TV_hours_reduced = annual_hours_short[0:-1:3]\n",
    "f2 = interpolate.interp1d(TV_hours_reduced,TV1,kind = 'linear')\n",
    "TV_interp = f2(annual_hours_short[0:-5:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists of initial and boundary conditions and empiric results for returns 1-5:\n",
    "\n",
    "t0_all = [hour1i, hour2i, hour3i, hour4i, hour5i]\n",
    "tf_all = [hour1i + int(13*24), hour2i + int(14*24), hour3i + int(12*24-4), hour4i + int(13*24-4), hour5i + int(14*24-2)]\n",
    "Nsea_all = [90, 111, 91, 148, 206] # in period 3 used final concentrations\n",
    "mi_all = [1.315*0.15, 1.315*0.15, 1.315*0.15, 1.306*0.15, 1.306*0.15]\n",
    "mf_real = [4590, 2781, 1120, 2001, 1069]\n",
    "Nint0_all = [2, 1.05, 0.65, 3, 1.06]# Nint0 of first period - assumed 2 (after 1 week starvation), and of forth assumed 3 (after fertilizing in Porter)\n",
    "Nintf_all = [1.05, 0.65, 0.98, 1.06, 1.40]\n",
    "functions = [Reading_val, Reading_val_IMS]\n",
    "TV_average = [TV1, TV2_average, TV3_average, TV4_average, TV5_average]\n",
    "IV_average = [1, IV2_average, IV3_average, IV4_average, IV5_average]\n",
    "xlabels_all = [['20 April', '27 April', '3 May'],['3 May', '10 May', '17 May'],['17 May', '23 May', '29 May'],['15 June', '22 june', '28 June'],['28 June', '5 July', '12 July']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = [1, 2, 4, 5]\n",
    "Errors = []\n",
    "Square_Errors = []\n",
    "for k in returns:\n",
    "    t0 = t0_all[k-1]\n",
    "    t = list(range(t0,tf_all[k-1]))\n",
    "    Nsea = Nsea_all[k-1]\n",
    "    Next0 = Nsea_all[k-1]\n",
    "    Nint0 = Nint0_all[k-1]\n",
    "    m0 = mi_all[k-1]\n",
    "    TV_reduced = TV_average[k-1][1:len(t)+1]\n",
    "    f1 = interpolate.interp1d(t, TV_reduced,kind = 'linear')    \n",
    "    f0 = interpolate.interp1d(annual_hours, I,kind = 'linear')\n",
    "\n",
    "    NSEA, NEXT, NINT, M, Total_N, T, Total_biomass, FINAL_M = [],[],[],[],[],[],[],[]\n",
    "\n",
    "    # setup initial conditions identical for all reactors\n",
    "    x0 = n_reactors*[Nsea, Next0, Nint0, m0]\n",
    "    args = (Nintcrit,Nintmax,Nintmin,Vmax,Ks,KN,miu,S,Z,KI,K0,Ka,Topt,Tmin,Tmax,losses20,\n",
    "            teta,Sopt,Smin,Smax, Qp, Qsea, Nsea,f1,f0,dilution,n,umol_to_percent_DW)\n",
    "\n",
    "    # solve the ODEs using the new syntax\n",
    "    sol = solve_ivp(Reading_val_IMS, [t[0], t[-1]], x0, args=args, t_eval = t)\n",
    "\n",
    "    # take the solution of the state variables:\n",
    "    M_farm, N_farm = [], []\n",
    "    NSEA.append(sol.y[0,:])\n",
    "    NEXT.append(sol.y[1,:])\n",
    "    NINT.append(sol.y[2,:])\n",
    "    M.append(sol.y[3,:])\n",
    "    M_farm.append((M[-1][-1] - m0) * 1.785)\n",
    "    N_farm.append((M[-1][-1] * NINT[-1][-1] * 1.785 / 100))\n",
    "    Total_biomass.append(round(sum(M_farm),3))\n",
    "    Total_N.append(round(sum(N_farm),4))\n",
    "\n",
    "    T.append(sol.t)\n",
    "    t = T[0]\n",
    "\n",
    "    final_m = round(M [-1][-1] * 1.785 / 0.15,4)\n",
    "    measured_m = round(mf_real[k-1] * 1.785 / 1000,4)\n",
    "    FINAL_M.append(final_m)\n",
    "    error = abs(round((measured_m - final_m) / measured_m,4))\n",
    "    Errors.append(error)\n",
    "    square_error = error**2\n",
    "    Square_Errors.append(square_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13772517017597039\n"
     ]
    }
   ],
   "source": [
    "RMSRE = (np.mean(Square_Errors))**0.5\n",
    "print(RMSRE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1374, 0.1281, 0.2004, 0.0206]\n",
      "0.121625\n",
      "0.06461874244365949\n"
     ]
    }
   ],
   "source": [
    "print(Errors)\n",
    "print(np.mean(Errors))\n",
    "print(np.std(Errors))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
